{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging of large dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d9ccb5959ff8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpymysql\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0myaml\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmerging\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymysql'"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "from yaml import load\n",
    "from datetime import datetime\n",
    "\n",
    "from merging import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as f:\n",
    "    config = load( f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(\n",
    "    host = config['mysql']['key1']['dbhost'],\n",
    "    port = comfig['mysql']['key1']['dbport'],\n",
    "    user = config['mysql']['key1']['dbuser'],\n",
    "    password = config['mysql']['key1']['dbpass'],\n",
    "    db = 'conversion',\n",
    "    cursorclass = pymysql.cursors.SSDictCursor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryOrdersTech = \"Select dateTime, type, region, source, medium, orders as value FROM {}.{};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersTechData = statusData('conversion', 'orders', connection, queryOrdersTech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i=0\n",
    "\n",
    "with open('joined_tables.txt', 'w') as f:\n",
    "    f.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format('dateTime', 'type', 'region', 'source', 'medium', 'visits', 'orders' ))\n",
    "    \n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(\"SELECT * FROM conversion.visits where dateTime >= '2017-06-01'\")\n",
    "        \n",
    "        for line in cursor:\n",
    "            \n",
    "            orders = searchForLine( line['dateTime'], line['type'], line['region'], line['source'], line['medium'], ordersTechData )\n",
    "            f.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(line['dateTime'], line['type'], line['region'], line['source'], line['medium'], line['visits'], orders))\n",
    "            \n",
    "            i += 1\n",
    "            if i % 10000 == 0:\n",
    "                print( i )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = True\n",
    "orders_dict = {}\n",
    "with open('orders_by_source.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if head:\n",
    "            head = False\n",
    "        else:\n",
    "            line = line.strip().split('\\t')\n",
    "            source = line[0]\n",
    "            orders_count = int(line[1])\n",
    "            orders_dict[source] = orders_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print(orders_dict['promo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание кейса для объединения таблиц\n",
    "# На данном занятии мы будем использовать данные о покупках из файла,\n",
    "# сгруппированных по источнику, каналу и дате, а также аналогичный файл по визитам на сайт, \n",
    "# часть из которых привела к покупке.\n",
    "\n",
    "# Файл с визитами по источникам (“visits_by_source.txt”)(в первом столбце стоит источник трафика, во втором — сумма визитов)\n",
    "# Файл с покупками по источникам (“orders_by_source.txt”)(в первом столбце стоит источник трафика, \n",
    "# во втором — количество покупок, в третьем — суммарная стоимость покупок)\n",
    "\n",
    "# Наша задача — посчитать конверсию из визитов в покупки в разрезе источников трафика.\n",
    "# Т. е. для каждой пары значений source и medium нам нужно взять количество визитов и покупок и совместить их в одной таблице.\n",
    "\n",
    "# Файл visits_by_source.txt может быть любого размера (мы обрабатываем его построчно). \n",
    "# Представим, что это выгрузка из базы данных на 50 Гб или поток данных в виде транзакций из базы данных.\n",
    "# То есть мы считаем файл условно «бесконечным».\n",
    "\n",
    "# Файл orders_by_source.txt помещается в оперативной памяти компьютера. \n",
    "# Однако в памяти мы можем обрабатывать довольно большие файлы.\n",
    "# Например, файл в 1 гигабайт свободно помещается в памяти даже не особо мощного ноутбука.\n",
    "# То есть файл большой, но помещается в оперативную память.\n",
    "\n",
    "# Наша задача будет состоять в следующем: нужно написать функцию, на вход которой\n",
    "# будем подавать очередную строчку из файла visits_by_source.txt. \n",
    "# В ответ должны получать количество покупок из файла orders_by_source.txt, \n",
    "# которое соответствует этой строчке. Т. е. в самом простом случае \n",
    "# в файле orders_by_source.txt надо найти строчку с таким же источником и вернуть значение из второго столбца\n",
    "\n",
    "def searchForLine( source, orders_dict ):\n",
    "    \"\"\"\n",
    "        Функция по названию источника source ищет соответствующую строку в файле orders_by_source.txt.\n",
    "    Возвращает количество покупок, соответствующих источнику source.\n",
    "        Если источник не найден, но возвращает 0.\n",
    "    Например:\n",
    "        >> searchForLine('burgerclub')\n",
    "        10\n",
    "        >> searchForLine('source_123')\n",
    "        0\n",
    "    \"\"\"\n",
    "    # Для получения определенного значения по названию источника отлично подойдет словарь.\n",
    "    # Можно было, например, поместить наши пары значений в набор листов и пробегать все его значения. \n",
    "    # Но это будет очень долго в случае больших файлов. К тому же если источника в файле покупок нет,\n",
    "    # то \"проход\" по этому листу будет впустую.\n",
    "    \n",
    "    if source in orders_dict:\n",
    "        return orders_dict[source]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(searchForLine('burgerclub', orders_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('joined_by_source.txt', 'w') as f_joined:\n",
    "    with open('visits_by_source.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            source = line[0]\n",
    "            visits = int(line[1])\n",
    "            orders = searchForLine(source, orders_dict)\n",
    "            f_joined.write('{}\\t{}\\t{}\\t{}\\n'.format(source, visits, orders, orders/visits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average coversion is 0.007\n"
     ]
    }
   ],
   "source": [
    "conv_sum = 0\n",
    "conv_count = 0\n",
    "with open('joined_by_source.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split('\\t')\n",
    "        conv_sum += float(line[3])\n",
    "        conv_count += 1\n",
    "print('Average coversion is {:.3f}'.format(conv_sum/conv_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение вложенного словаря\n",
    "\n",
    "# Поиск по одному столбцу — ситуация не самая часто встречающаяся. \n",
    "# Обычно столбцов гораздо больше. Да и файлы, с которыми приходится работать, на практике гораздо сложнее.\n",
    "\n",
    "# Для удобства представим более реальную таблицу с покупками. Например, на 4 миллиона строк и 500 Мб на диске.\n",
    "# Если необходимо найти в этой таблице нужную комбинацию source и medium,\n",
    "# надо учитывать, что эта пара может встретиться в любой из 4 миллионов строк. \n",
    "# Также может быть ситуация, что для этой комбинации source и medium не было ни одной покупки.\n",
    "\n",
    "# Для ускорения нашего поиска давайте заменим таблицу из столбцов source, medium и количества покупок вложенным словарем.\n",
    "\n",
    "# Что дает такая структура?\n",
    "# Теперь, чтобы найти нужную комбинацию значений source и medium, нужно сделать два простых шага:\n",
    "\n",
    "# 1. Из 2000 значений source определить, есть ли среди них нужный нам. Если его не оказалось, то сразу возвращаем 0 покупок.\n",
    "\n",
    "# 2. Если значение source есть в первичных ключах, то ищем значение medium в списке из вторичных ключей, \n",
    "# которые оказались у источника source (кстати, их может быть всего несколько).\n",
    "# Логика такая же: если ключ найден, возвращаем значение покупок для первичного ключа source и вторичного medium. \n",
    "# Если не найден, то возвращаем 0.\n",
    "\n",
    "# Итого для поиска среди 4 000 000 строк нам нужно сначала проверить наличие очередного значения в списке ключей из source,\n",
    "# а затем — в списке из medium. Это намного быстрее, чем любой последовательный мониторинг этих 4 миллионов строк.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод setdefault\n",
    "# Можно переписать этот код с помощью метода setdefault. \n",
    "\n",
    "# orders_dict = {}\n",
    "# if 'google' in orders_dict:\n",
    "    # orders_dict['google'] += 1\n",
    "# else:\n",
    "    # orders_dict['google'] = 1\n",
    "# print(orders_dict)\n",
    "\n",
    "#>> {'google': 1}\n",
    "\n",
    "# Этот метод проверяет есть ли в словаре указанный ключ 'google'. \n",
    "# Если есть, то оставляет соответствующее значение ключа прежним.\n",
    "# Если ключа не оказалось, то подставляет указанное нами значение (в примере это значение 0). \n",
    "# Тем самым после применения метода setdefault можно смело использовать прибавление 1 к ключу 'google'\n",
    "# независимо от того, был ли этот ключ в словаре раньше\n",
    "\n",
    "# orders_dict = {}\n",
    "# orders_dict.setdefault('google', 0)\n",
    "# orders_dict['google'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_dict = {}\n",
    "with open('orders_by_source_and_medium.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split('\\t')\n",
    "        source = line[0]\n",
    "        medium = line[1]\n",
    "        orders_count = int(line[2])\n",
    "        orders_dict.setdefault(source, {})\n",
    "        orders_dict[source].setdefault(medium, 0)\n",
    "        orders_dict[source][medium] = orders_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand': 6, 'sem': 56, 'seo': 15}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_dict['google']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchForLine( source, medium, orders_dict):\n",
    "    \"\"\"\n",
    "        Функция по названию источника source и канала medium ищет соответствующую строку в словаре, составленному из данных файла orders_by_source.txt.\n",
    "    Возвращает количество покупок, соответствующих источнику source и каналу medium.\n",
    "        Если источник не найден, но возвращает 0.\n",
    "    Например:\n",
    "        >> searchForLine('google', 'seo', orders_dict)\n",
    "        15\n",
    "        >> searchForLine('google_123', 'seo', orders_dict)\n",
    "        0\n",
    "    \"\"\"\n",
    "    if source in orders_dict:\n",
    "        if medium in orders_dict[source]:\n",
    "            return orders_dict[source][medium]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchForLine('google', 'sem', orders_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('joined_by_source_medium', 'w') as f_joined:\n",
    "    with open('visits_by_source_and_medium.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            source = line[0]\n",
    "            medium = line[1]\n",
    "            visits = int(line[2])\n",
    "            orders = searchForLine(source, medium, orders_dict)\n",
    "            f_joined.write('{}\\t{}\\t{}\\t{}\\t{:.3f}\\n'.format(source,medium, visits, orders, orders/visits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "# 5. Дан словарь:\n",
    "# total_costs = { 'google': 1319, 'yandex': 1818, 'promo': 1181 }\n",
    "# Необходимо вывести названия источников, отсортированных по алфавиту в обратном порядке\n",
    "# sorted( total_costs.keys(), reverse = True )\n",
    "\n",
    "# 7. Как нам перевести следующую дату в тип datetime: \n",
    "# date_string = '23.02.2017 15:20'\n",
    "# datetime.strptime( date_string, '%d.%m.%Y %H:%M' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA UNIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПОНЯТИЕ РЕКУРСИИ\n",
    "\n",
    "# Вы наверняка заметили, что в прошлом шаге при учете столбца medium наш код усложнился.\n",
    "# Приходилось каждый раз проверять наличие новых ключей или использовать setdefault для всех уровней.\n",
    "# В реальных задачах столбцов будет больше. Например, в некоторых задачах приходится объединять таблицы\n",
    "# по 5 и более столбцам. Если обходиться проверками или методом setdefault на всех возможных уровнях словарей,\n",
    "# то наш код будет быстро разрастаться или станет медленным, т. к. заранее сложно предсказать структуру\n",
    "# вложенных уровней словаря orders_dict.\n",
    "\n",
    "# В текущем модуле под рекурсией мы будем понимать алгоритм,\n",
    "# в котором функция может вызывать сама себя с изменяющимся аргументом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrease_and_print_i( i ):\n",
    "    if i > 1:\n",
    "        print(i)\n",
    "        return decrease_and_print_i( i - 1 )\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рекурсия и словари\n",
    "\n",
    "# Все прошлые примеры можно было без труда решить с помощью циклов. Давайте сделаем пример, \n",
    "# в котором использование рекурсии позволит нам перевести лист\n",
    "# >> line = ['2016-10-01', 'burgerclub', 'cpa-partners', 1]\n",
    "# в словарь\n",
    "# >> dict2fill = {'2016-10-01': {'burgerclub': {'cpa-partners': 1}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = ['2016-10-01', 'burgerclub', 'cpa-partners', 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillLevels( lineRemainder ):\n",
    "    \"\"\"\n",
    "    На вход функция принимает часть листа line.\n",
    "    Берет его первый элемент lineRemainder[0] и вызывает себя с остатком листа line, т. е. с элементами lineRemainder[1:].\n",
    "    Так продолжаем до тех пор, пока в lineRemainder не останется один элемент\n",
    "    \n",
    "    Пример\n",
    "    >> fillLevels( ['2016-10-01', 'burgerclub', 'cpa-partners', 1] )\n",
    "    {'2016-10-01': {'burgerclub': {'cpa-partners': 1}}}\n",
    "\n",
    "    \"\"\"\n",
    "    # словарь, который будем пошагово заполнять\n",
    "    dict2fill = {}\n",
    "    if len(lineRemainder) > 1:\n",
    "        dict2fill[lineRemainder[0]] = fillLevels(lineRemainder[1:])\n",
    "    else:\n",
    "        return lineRemainder[0]\n",
    "    return dict2fill\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2016-10-01': {'burgerclub': {'cpa-partners': 1}}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fillLevels(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = [x for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {1: {2: {3: {4: {5: {6: {7: {8: {9: {10: {11: {12: {13: {14: {15: {16: {17: {18: {19: {20: {21: {22: {23: {24: {25: {26: {27: {28: {29: {30: {31: {32: {33: {34: {35: {36: {37: {38: {39: {40: {41: {42: {43: {44: {45: {46: {47: {48: {49: {50: {51: {52: {53: {54: {55: {56: {57: {58: {59: {60: {61: {62: {63: {64: {65: {66: {67: {68: {69: {70: {71: {72: {73: {74: {75: {76: {77: {78: {79: {80: {81: {82: {83: {84: {85: {86: {87: {88: {89: {90: {91: {92: {93: {94: {95: {96: {97: {98: 99}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fillLevels(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkLevels( levelDict, level, line ):\n",
    "    if line[level] in levelDict:\n",
    "        checkLevels(levelDict[ line[level] ], level+1, line)\n",
    "        return levelDict\n",
    "    else:\n",
    "        levelDict[ line[level] ] = fillLevels( line[ level+1:] )\n",
    "        return levelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "\n",
    "['2016-10-01', 'google', 'sem', 5],\n",
    "\n",
    "['2016-10-01', 'google', 'seo', 1],\n",
    "\n",
    "['2016-10-01', 'newsletter', 'email', 1]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2016-10-01': {'google': {'sem': 5, 'seo': 1}, 'newsletter': {'email': 1}}}\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for line in data:\n",
    "    data_dict = checkLevels( data_dict, 0, line)\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "\n",
    "['2018-01-01', 'google', 'cpc', 'ДФО', 'кампания_1', 'Хабаровск', 114],\n",
    "\n",
    "['2018-01-01', 'google', 'cpc', 'ДФО', 'кампания_2', 'Владивосток', 536],\n",
    "\n",
    "['2018-01-01', 'google', 'cpc', 'ДФО', 'кампания_1', 'Магадан', 436]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2018-01-01': {'google': {'cpc': {'ДФО': {'кампания_1': {'Хабаровск': 114, 'Магадан': 436}, 'кампания_2': {'Владивосток': 536}}}}}}\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for line in data:\n",
    "    data_dict = checkLevels( data_dict, 0, line)\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict['2018-01-01']['google']['cpc']['ДФО'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLineValue( finalDict, line ):\n",
    "    if len( line ) > 1:\n",
    "        if line[0] in finalDict:\n",
    "            return findLineValue( finalDict[line[0]], line[1:])\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if line[0] in finalDict:\n",
    "            return finalDict[ line[0]]\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "\n",
    "['2016-10-01', 'google', 'sem', 5],\n",
    "\n",
    "['2016-10-01', 'google', 'seo', 1],\n",
    "\n",
    "['2016-10-01', 'newsletter', 'email', 1]\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2016-10-01': {'google': {'sem': 5, 'seo': 1}, 'newsletter': {'email': 1}}}\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for line in data:\n",
    "    data_dict = checkLevels( data_dict, 0, line)\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findLineValue( data_dict, ['2016-10-01', 'google', 'sem'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findLineValue( data_dict, ['2018-01-01', 'google', 'sem'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "\n",
    "['2018-01-01', 'google', 'cpc', 'ДФО', 'кампания_1', 'Хабаровск', 114],\n",
    "\n",
    "['2018-01-01', 'google', 'cpc', 'ДФО', 'кампания_2', 'Владивосток', 536],\n",
    "\n",
    "['2018-01-01', 'google', 'cpc', 'ДФО', 'кампания_1', 'Магадан', 436]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2018-01-01': {'google': {'cpc': {'ДФО': {'кампания_1': {'Хабаровск': 114, 'Магадан': 436}, 'кампания_2': {'Владивосток': 536}}}}}}\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for line in data:\n",
    "    data_dict = checkLevels( data_dict, 0, line)\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = 26800\n",
    "conversion = float(findLineValue( data_dict, ['2018-01-01', 'google', 'cpc', 'ДФО', 'кампания_2', 'Владивосток']))/ visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
